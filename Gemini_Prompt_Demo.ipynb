{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnBYUGgwUgYry7iAUAyuXf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpupkies/Jim-Pupkies/blob/master/Gemini_Prompt_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sync Screenshots from Google Drive\n",
        "\n",
        "This cell mounts Google Drive and copies the permanent source screenshots into the notebook’s local `/content/screenshots` folder.  \n",
        "This ensures that all screenshot display calls will work consistently, even after restarting the runtime.\n"
      ],
      "metadata": {
        "id": "mG1Jn2lQVtDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Permanent source storage in Google Drive\n",
        "src = \"/content/drive/MyDrive/AI_Portfolio/Gemini_Prompt_Demo/screenshots\"\n",
        "dst = \"/content/screenshots\"\n",
        "\n",
        "# Ensure destination exists\n",
        "os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "# Sync files\n",
        "if os.path.exists(src):\n",
        "    for f in os.listdir(src):\n",
        "        src_file = os.path.join(src, f)\n",
        "        dst_file = os.path.join(dst, f)\n",
        "        shutil.copy(src_file, dst_file)\n",
        "    print(\"Screenshots synced to /content/screenshots\")\n",
        "else:\n",
        "    print(\"Source screenshots folder missing:\", src)\n",
        "\n",
        "# Confirm presence\n",
        "print(\"Files now in /content/screenshots:\", os.listdir(dst))\n"
      ],
      "metadata": {
        "id": "g63w5R48TEvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini Interactive Prompt Demo\n",
        "\n",
        "This notebook demonstrates an **interactive interface** for testing prompts with multiple AI models (Gemini, GPT-4, and Claude). It is fully self-contained and designed for portfolio purposes.\n",
        "\n",
        "## How to Use\n",
        "\n",
        "1. **Enter your prompt** in the text box provided.\n",
        "2. **Select a model** from the dropdown menu.\n",
        "3. Optionally, adjust:\n",
        "   - **Temperature**: Controls creativity of the output.\n",
        "   - **Max Tokens**: Maximum length of the generated response.\n",
        "4. Click **Run Prompt** to see the output displayed below.\n",
        "\n",
        "## Example Prompts\n",
        "\n",
        "| Prompt | Description / Caption |\n",
        "|--------|----------------------|\n",
        "| `Generate three unique marketing slogans for a coffee brand.` | Demonstrates multi-output generation and creativity. |\n",
        "| `Write a short poem about AI helping humans.` | Shows creative, expressive output. |\n",
        "| `Explain the difference between supervised and unsupervised learning in simple terms.` | Shows ability to summarize technical concepts clearly. |\n",
        "| `List five fun facts about space.` | Demonstrates structured, list-based outputs. |\n",
        "\n",
        "> **Note:** Outputs are simulated for demonstration purposes. In a fully connected setup, prompts would generate live responses from the selected model.\n",
        "\n",
        "## Portfolio Notes\n",
        "\n",
        "- Each prompt demonstrates the AI model’s capabilities clearly and interactively.\n",
        "- Captions explain the intended purpose of each example.\n",
        "- The interface is entirely separate from the main batch workflow, keeping this notebook clean and self-contained.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zj75T_XaSNx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Setup"
      ],
      "metadata": {
        "id": "IfeNJnnySS-q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxJOI282SDDS"
      },
      "outputs": [],
      "source": [
        "# Step 1: Setup\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "\n",
        "# Optional: import your existing helper function if accessible\n",
        "# from your_main_notebook_helpers import ask_gemini\n",
        "\n",
        "# Secure API key input\n",
        "gemini_api_key = widgets.Password(\n",
        "    description='Gemini API Key:',\n",
        "    placeholder='Enter your key here',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "display(gemini_api_key)\n",
        "\n",
        "# Function to run a single prompt (replace with Gemini API call)\n",
        "def run_prompt(prompt, model='Gemini', temperature=0.7, max_tokens=200):\n",
        "    # Simulated multi-output for demo\n",
        "    if \"marketing slogans\" in prompt.lower():\n",
        "        response = (\n",
        "            \"1. Brew Joy, Every Cup.\\n\"\n",
        "            \"2. Wake Up Your Senses.\\n\"\n",
        "            \"3. Coffee That Inspires.\"\n",
        "        )\n",
        "    else:\n",
        "        response = f\"[{model} output for prompt: '{prompt}']\"\n",
        "    return response\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image, Markdown\n",
        "\n",
        "# List of screenshots with captions\n",
        "screenshots = [\n",
        "    (\"/content/screenshots/Step1_Setup.png\", \"Step 1: Setup\"),\n",
        "]\n",
        "\n",
        "# Display each screenshot with its caption\n",
        "for path, caption in screenshots:\n",
        "    display(Markdown(f\"### {caption}\"))\n",
        "    display(Image(filename=path))\n"
      ],
      "metadata": {
        "id": "VuSPxhRoSZgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, you have:\n",
        "\n",
        "- Secure API input.\n",
        "\n",
        "- Placeholder function for running prompts.\n",
        "\n",
        "- All packages imported."
      ],
      "metadata": {
        "id": "wvowDY5LSbY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Interactive Prompt Interface"
      ],
      "metadata": {
        "id": "yCFA7CBlSczL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Interactive Interface\n",
        "\n",
        "# Text input for the prompt\n",
        "prompt_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Type your prompt here...',\n",
        "    description='Prompt:',\n",
        "    layout=widgets.Layout(width='80%', height='80px')\n",
        ")\n",
        "\n",
        "# Dropdown for model selection\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=['Gemini', 'GPT-4', 'Claude'],\n",
        "    value='Gemini',\n",
        "    description='Model:'\n",
        ")\n",
        "\n",
        "# Sliders for temperature and max tokens\n",
        "temperature_slider = widgets.FloatSlider(\n",
        "    value=0.7,\n",
        "    min=0.0,\n",
        "    max=1.0,\n",
        "    step=0.05,\n",
        "    description='Temperature:'\n",
        ")\n",
        "\n",
        "max_tokens_slider = widgets.IntSlider(\n",
        "    value=200,\n",
        "    min=50,\n",
        "    max=1000,\n",
        "    step=50,\n",
        "    description='Max Tokens:'\n",
        ")\n",
        "\n",
        "# Output display area\n",
        "output_area = widgets.Output(layout={'border': '1px solid black', 'width': '80%'})\n",
        "\n",
        "# Run button\n",
        "run_button = widgets.Button(description='Run Prompt', button_style='success')\n",
        "\n",
        "# Function to handle button click\n",
        "def on_run_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        prompt = prompt_input.value\n",
        "        model = model_dropdown.value\n",
        "        temperature = temperature_slider.value\n",
        "        max_tokens = max_tokens_slider.value\n",
        "\n",
        "        if not prompt.strip():\n",
        "            print(\"Please enter a prompt to run.\")\n",
        "            return\n",
        "\n",
        "        start_time = time.time()\n",
        "        response = run_prompt(prompt, model=model, temperature=temperature, max_tokens=max_tokens)\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Display results\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "        print(f\"Model: {model}\")\n",
        "        print(f\"Temperature: {temperature}, Max Tokens: {max_tokens}\")\n",
        "        print(f\"Response (Time: {end_time - start_time:.2f}s):\\n\")\n",
        "        print(response)\n",
        "\n",
        "run_button.on_click(on_run_button_clicked)\n",
        "\n",
        "# Display the interactive widgets\n",
        "display(prompt_input, model_dropdown, temperature_slider, max_tokens_slider, run_button, output_area)\n"
      ],
      "metadata": {
        "id": "AkmBHueYShbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image, Markdown\n",
        "\n",
        "# List of screenshots with captions\n",
        "screenshots = [\n",
        "    (\"/content/screenshots/Step2_Interactive_Prompt_Interface.png\", \"Step 2: Interactive Prompt Interface\"),\n",
        "]\n",
        "\n",
        "# Display each screenshot with its caption\n",
        "for path, caption in screenshots:\n",
        "    display(Markdown(f\"### {caption}\"))\n",
        "    display(Image(filename=path))\n"
      ],
      "metadata": {
        "id": "jhXweQIdSjrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features added:\n",
        "\n",
        "- Users can enter any prompt in a text box.\n",
        "\n",
        "- Choose between Gemini, GPT-4, or Claude.\n",
        "\n",
        "- Adjust temperature and max tokens.\n",
        "\n",
        "- Results are displayed in a scrollable, styled output area.\n",
        "\n",
        "- Measures execution time and prints model parameters for clarity."
      ],
      "metadata": {
        "id": "Of1esTy7SlPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Example Prompts and Captions\n",
        "1. Purpose\n",
        "\n",
        "- Show multiple demo prompts with pre-filled examples.\n",
        "\n",
        "- Display outputs in a clear, visually appealing way.\n",
        "\n",
        "- Add captions explaining what each output represents, so a portfolio viewer immediately understands the notebook’s purpose."
      ],
      "metadata": {
        "id": "RYNupAVnSmsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Example Prompts\n",
        "We can create a small table of prompts, each with an intended output type. These will use the simulated run_prompt() function for the portfolio demo.\n",
        "\n",
        "Example table:\n",
        "\n",
        "## Example Prompts and Captions\n",
        "\n",
        "| Prompt | Description / Caption |\n",
        "|--------|----------------------|\n",
        "| `Generate three unique marketing slogans for a coffee brand.` | Demonstrates multi-output generation and creativity. |\n",
        "| `Write a short poem about AI helping humans.` | Shows creative, expressive output. |\n",
        "| `Explain the difference between supervised and unsupervised learning in simple terms.` | Shows ability to summarize technical concepts clearly. |\n",
        "| `List five fun facts about space.` | Demonstrates structured, list-based outputs. |\n",
        "\n",
        "> **Note:** The outputs shown in this notebook are simulated for demo purposes. In a fully connected setup, each prompt would be sent to the selected AI model (Gemini, GPT-4, or Claude) and generate live responses.\n"
      ],
      "metadata": {
        "id": "mUAovC2sSpAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Implement in Notebook\n",
        "\n",
        "\n",
        "You can add a new code cell like this:"
      ],
      "metadata": {
        "id": "D4r4U8XdSsZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Example Prompts with Captions\n",
        "example_prompts = [\n",
        "    (\"Generate three unique marketing slogans for a coffee brand.\",\n",
        "     \"Demonstrates multi-output generation and creativity.\"),\n",
        "\n",
        "    (\"Write a short poem about AI helping humans.\",\n",
        "     \"Shows creative, expressive output.\"),\n",
        "\n",
        "    (\"Explain the difference between supervised and unsupervised learning in simple terms.\",\n",
        "     \"Shows ability to summarize technical concepts clearly.\"),\n",
        "\n",
        "    (\"List five fun facts about space.\",\n",
        "     \"Demonstrates structured, list-based outputs.\")\n",
        "]\n",
        "\n",
        "for prompt, caption in example_prompts:\n",
        "    output = run_prompt(prompt)  # uses simulated run_prompt function\n",
        "    print(f\"Prompt: {prompt}\\nCaption: {caption}\\nOutput:\\n{output}\\n{'-'*60}\\n\")\n"
      ],
      "metadata": {
        "id": "ipG4NnKLSv2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image, Markdown\n",
        "\n",
        "# List of screenshots with captions\n",
        "screenshots = [\n",
        "    (\"/content/screenshots/Step3_Example_Prompts_with_Captions.png\", \"Step 3: Example Prompts with Captions\")\n",
        "]\n",
        "\n",
        "# Display each screenshot with its caption\n",
        "for path, caption in screenshots:\n",
        "    display(Markdown(f\"### {caption}\"))\n",
        "    display(Image(filename=path))\n"
      ],
      "metadata": {
        "id": "Ae5-2GZ4SxxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Portfolio Notes\n",
        "\n",
        "Each block includes:\n",
        "\n",
        "- The prompt so viewers see the input.\n",
        "\n",
        "- A caption describing the purpose.\n",
        "\n",
        "- The output, formatted clearly.\n",
        "\n",
        "This is enough to demonstrate your interface and batch functionality visually without needing real API calls."
      ],
      "metadata": {
        "id": "ySMglqb_SzO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features:\n",
        "\n",
        "- Clean Markdown table with two columns: prompt & caption.\n",
        "\n",
        "- Easy to read and visually aligned for a portfolio.\n",
        "\n",
        "- Includes a note explaining the simulated outputs, so viewers understand the context.\n"
      ],
      "metadata": {
        "id": "hlgEEIgNS0tU"
      }
    }
  ]
}